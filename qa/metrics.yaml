# you must define metadata about all your objective figures of merits
available_metrics:
  reads/s:
    label: reads
    suffix: "/s"
    smaller_is_better: false
  writes/s:
    label: writes
    suffix: "/s"
    smaller_is_better: false
  fsyncs/s:
    label: fsyncs
    suffix: "/s"
    smaller_is_better: false
  read_mib/s:
    label: Read Throughput
    suffix: MiB/s
    smaller_is_better: false
  written_mib/s:
    label: Write Throughput
    suffix: MiB/s
    smaller_is_better: false

  latency_ms_min:
    label: Latency (min)
    suffix: ms
  latency_ms_avg:
    label: Latency (avg)
    suffix: ms
  latency_ms_max:
    label: Latency (max)
    suffix: ms
  latency_ms_95th_percentile:
    label: Latency (95th)
    suffix: ms

  total_time:
    label: Total Time
    suffix: s
  execution_time_avg:
    label: Execution Time Avg
    short_label: Time Avg
    suffix: s
  execution_time_avg:
    label: Execution Time StdDev
    short_label: Time StdDev
    suffix: s
  
    


# Below we define which metrics the GUI should show
default_metric: reads/s

# will be shown in the summary histogramms
summary_metrics:
  - execution_time_avg
  - reads/s
  - writes/s
  - fsyncs/s
  - read_mib/s
  - written_mib/s
  - latency_ms_min
  - latency_ms_avg
  - latency_ms_max
  - latency_ms_95th_percentile

# will be shown in the results table and in the output cards
main_metrics:
  - execution_time_avg
  - reads/s
  - writes/s
  - fsyncs/s
  - read_mib/s
  - written_mib/s
  - latency_ms_min
  - latency_ms_avg
  - latency_ms_max
  - latency_ms_95th_percentile